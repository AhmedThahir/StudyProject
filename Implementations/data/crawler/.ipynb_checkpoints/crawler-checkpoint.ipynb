{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get basic players information for all players\n",
    "base_url = \"https://sofifa.com/players?offset=\"\n",
    "columns = ['ID', 'Name', 'Age', 'Photo', 'Nationality', 'Flag', 'Overall', 'Potential', 'Club', 'Club Logo', 'Value', 'Wage', 'Special']\n",
    "data = pd.DataFrame(columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for offset in range(0, 300):\n",
    "    url = base_url + str(offset * 61)\n",
    "    source_code = requests.get(url)\n",
    "    plain_text = source_code.text\n",
    "    soup = BeautifulSoup(plain_text, 'html.parser')\n",
    "    table_body = soup.find('tbody')\n",
    "    for row in table_body.findAll('tr'):\n",
    "        td = row.findAll('td')\n",
    "        picture = td[0].find('img').get('data-src')\n",
    "        pid = td[0].find('img').get('id')\n",
    "        nationality = td[1].find('a').get('title')\n",
    "        flag_img = td[1].find('img').get('data-src')\n",
    "        name = td[1].findAll('a')[1].text\n",
    "        age = td[2].find('div').text.strip()\n",
    "        overall = td[3].text.strip()\n",
    "        potential = td[4].text.strip()\n",
    "        club = td[5].find('a').text\n",
    "        club_logo = td[5].find('img').get('data-src')\n",
    "        value = td[6].text.strip()\n",
    "        wage = td[7].text.strip()\n",
    "        special = td[8].text.strip()\n",
    "        player_data = pd.DataFrame([[pid, name, age, picture, nationality, flag_img, overall, potential, club, club_logo, value, wage, special]])\n",
    "        player_data.columns = columns\n",
    "        data = data.append(player_data, ignore_index=True)\n",
    "data = data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get detailed player information from player page\n",
    "detailed_columns = ['Preferred Foot', 'International Reputation', 'Weak Foot', 'Skill Moves', 'Work Rate', 'Body Type', 'Real Face', 'Position', 'Jersey Number', 'Joined', 'Loaned From', 'Contract Valid Until', 'Height', 'Weight', 'LS', 'ST', 'RS', 'LW', 'LF', 'CF', 'RF', 'RW', 'LAM', 'CAM', 'RAM', 'LM', 'LCM', 'CM', 'RCM', 'RM', 'LWB', 'LDM', 'CDM', 'RDM', 'RWB', 'LB', 'LCB', 'CB', 'RCB', 'RB', 'Crossing', 'Finishing', 'HeadingAccuracy', 'ShortPassing', 'Volleys', 'Dribbling', 'Curve', 'FKAccuracy', 'LongPassing', 'BallControl', 'Acceleration', 'SprintSpeed', 'Agility', 'Reactions', 'Balance', 'ShotPower', 'Jumping', 'Stamina', 'Strength', 'LongShots', 'Aggression', 'Interceptions', 'Positioning', 'Vision', 'Penalties', 'Composure', 'Marking', 'StandingTackle', 'SlidingTackle', 'GKDiving', 'GKHandling', 'GKKicking', 'GKPositioning', 'GKReflexes', 'ID']\n",
    "detailed_data = pd.DataFrame(index = range(0, data.count()[0]), columns = detailed_columns)\n",
    "detailed_data.ID = data.ID.values\n",
    "\n",
    "player_data_url = 'https://sofifa.com/player/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id in data.ID:\n",
    "    url = player_data_url + str(id)\n",
    "    source_code = requests.get(url)\n",
    "    plain_text = source_code.text\n",
    "    soup = BeautifulSoup(plain_text, 'html.parser')\n",
    "    skill_map = {}\n",
    "    columns = soup.find('div', {'class': 'teams'}).find('div', {'class': 'columns'}).findAll('div', {'class': 'column col-4'})\n",
    "    for column in columns:\n",
    "        skills = column.findAll('li')\n",
    "        for skill in skills:\n",
    "            if(skill.find('label') != None):\n",
    "                label = skill.find('label').text\n",
    "                value = skill.text.replace(label, '').strip()\n",
    "                skill_map[label] = value\n",
    "    meta_data = soup.find('div', {'class': 'meta'}).text.split(' ')\n",
    "    length = len(meta_data)\n",
    "    weight = meta_data[length - 1]\n",
    "    height = meta_data[length - 2].split('\\'')[0] + '\\'' + meta_data[length - 2].split('\\'')[1].split('\\\"')[0]\n",
    "    skill_map[\"Height\"] = height\n",
    "    skill_map['Weight'] = weight\n",
    "    if('Position' in skill_map.keys()):\n",
    "        if skill_map['Position'] in ('', 'RES', 'SUB'):\n",
    "            skill_map['Position'] = soup.find('article').find('div', {'class': 'meta'}).find('span').text\n",
    "        if(skill_map['Position'] != 'GK'):\n",
    "            card_rows = soup.find('aside').find('div', {'class': 'card mb-2'}).find('div', {'class': 'card-body'}).findAll('div', {'class': 'columns'})\n",
    "            for c_row in card_rows:\n",
    "                attributes = c_row.findAll('div', {'class': re.compile('column col-sm-2 text-center')})\n",
    "                for attribute in attributes:\n",
    "                    if(attribute.find('div')):\n",
    "                        name = ''.join(re.findall('[a-zA-Z]', attribute.text))\n",
    "                        value = attribute.text.replace(name, '').strip()\n",
    "                        skill_map[str(name)] = value\n",
    "    sections = soup.find('article').findAll('div', {'class': 'mb-2'})[1:3]\n",
    "    first = sections[0].findAll('div', {'class': 'column col-4'})\n",
    "    second = sections[1].findAll('div', {'class': 'column col-4'})[:-1]\n",
    "    sections = first + second\n",
    "    for section in sections:\n",
    "        items = section.find('ul').findAll('li')\n",
    "        for item in items:\n",
    "            value = int(re.findall(r'\\d+', item.text)[0])\n",
    "            name = ''.join(re.findall('[a-zA-Z]*', item.text))\n",
    "            skill_map[str(name)] = value\n",
    "    for key, value in skill_map.items():\n",
    "        detailed_data.loc[detailed_data.ID == id, key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = pd.merge(data, detailed_data, how = 'inner', on = 'ID')\n",
    "full_data.to_csv('data.csv', encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
